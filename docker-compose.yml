services:
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres_service
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    labels:
      lagoon.type: postgres

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres/postgres_service
      SECRET_KEY: "dKq2BK3pqGQfNqC7SK8ZxNCdqJnGV4F9"  # More secure key for development
      OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED: "true"
      OTEL_SERVICE_NAME: "backend-service"
      OTEL_TRACES_EXPORTER: "otlp"
      OTEL_METRICS_EXPORTER: "otlp"
      OTEL_EXPORTER_OTLP_PROTOCOL: "grpc"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4317"
      OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST: "content-type,user-agent"
    ports:
      - "8800:8800"
    volumes:
      - ./app:/app/app
    depends_on:
      postgres:
        condition: service_healthy
      otel-collector:
        condition: service_started
    labels:
      lagoon.type: python

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    command:
      - "npm"
      - "run"
      - "dev"
    volumes:
      - ./frontend:/app
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8800
    # user: '10000'
    labels:
      lagoon.type: node

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./ollama-init.sh:/usr/local/bin/ollama-init.sh
    entrypoint: ["/bin/sh", "/usr/local/bin/ollama-init.sh"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    labels:
      lagoon.type: none

  litellm:
    image: ghcr.io/berriai/litellm-database:main-latest
    ports:
      - "4000:4000" # Map the container port to the host, change the host port if necessary
    environment:
        DATABASE_URL: "postgresql://llmproxy:dbpassword9090@litellm_db:5432/litellm"
        STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI
        LITELLM_MASTER_KEY: "sk-1234"
        OTEL_EXPORTER: "otlp_grpc"
        OTEL_ENDPOINT: "http://otel-collector:4317"
        OLLAMA_BASE_URL: "http://ollama:11434"
    depends_on:
      - litellm_db
      - otel-collector
      - ollama
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:4000/health/liveliness || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - ./litellm_config.yaml:/app/config.yaml # Mount the local configuration file
    command: [ "--config", "/app/config.yaml"]
    labels:
      lagoon.type: none

  litellm_db:
    image: postgres:16
    restart: always
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    volumes:
      - litellm_postgres_data:/var/lib/postgresql/data  # Persists Postgres data across container restarts
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10
    labels:
      lagoon.type: none

  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"   # OTLP gRPC - needed for receiving traces/metrics
      - "4318:4318"   # OTLP HTTP
      - "8889:8889"   # Prometheus metrics
    depends_on:
      - jaeger
    labels:
      lagoon.type: none

  jaeger:
    image: jaegertracing/jaeger:latest
    ports:
      - "16686:16686"  # UI only - remove the 4317 port
    labels:
      lagoon.type: none

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    labels:
      lagoon.type: none

volumes:
  postgres_data:
  litellm_postgres_data:
    name: litellm_postgres_data
  ollama_data: